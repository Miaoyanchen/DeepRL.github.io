---
title: "A Comprehensive Introduction to Deep Reinforcement Learning"
author: "Miaoyan Chen and Zhaoxiang Ding"
date: "`r Sys.Date()`"
output: html_document
bibliography: deepRL.references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(fig.height = 4)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(eval = T)
knitr::opts_chunk$set(fig.align="center")
```

## Table of Contents

1.  Preamble

2.  Summary of Notations

3.  Reinforcement Learning

4.  Deep Reinforcement Learning

## Preamble

Whether we are engaging in a daily conversation or to driving a vehicle, essentially we are picking up on our surrounding environment and making a response simultaneously to the changes in the environment. Essentially, we are learning from our interaction with the environment and executing an action in return. This is the foundation idea that lies in all learning and intelligence [@sutton2018]. A machine learning technique to train software to make decision to achieve the optimal result by performing a sequence of actions in an environment is known as *reinforcement learning* [citation]. A reinforcement learning environment is formalized by an optimal control of Markov decision processes, which can be decompose into three essential parts - sensation, action, and goal [@sutton2018]. A learning agent should be able to sense the state of the environment, and takes series of actions that effects the state and achieve a goal overtime.

The idea of reinforcement learning is further extended to *deep reinforcement learning* that handles more sophisticated tasks. Deep reinforcement learning allows the agent to perform on real-world complexity in higher dimensions by training through deep neural networks. A novel artificial agent, deep Q-network agent was first introduced by Mnih et al. (2015).

## Summary of Notations

| Variable   | Definition                                                  |
|------------|-------------------------------------------------------------|
| $s$        | state                                                       |
| $a$        | action                                                      |
| $t$        | discrete time step                                          |
| $\pi$      | policy, decision rule                                       |
|            |                                                             |
| $s_t$      | state at time $t$                                           |
| $a_t$      | game actions selected from a set of actions                 |
| $x_t$      | result form emulator in the form of vector of pixel values  |
| $r_t$      | reward in game                                              |
| $\gamma$   | discount rate parameter per time step (default set to 0.99) |
| $Q^*(s,a)$ | maximum expected return achieved by policy                  |
| $\theta$   | weight parameter                                            |
| $R_t$      | total reward at time t, dependent                           |

## Reinforcement Learning

### Q-learning Algorithm

## Deep Reinforcement Learning

### A Novel Artificial Agent - Deep Q network (DQN)

### References

::: {#refs}
:::
